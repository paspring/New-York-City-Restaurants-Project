{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-Levenshtein\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/a9/d1785c85ebf9b7dfacd08938dd028209c34a0ea3b1bcdb895208bd40a67d/python-Levenshtein-0.12.0.tar.gz (48kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 7.0MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/envs/Python36/lib/python3.6/site-packages (from python-Levenshtein) (40.8.0)\n",
      "Building wheels for collected packages: python-Levenshtein\n",
      "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/dsxuser/.cache/pip/wheels/de/c2/93/660fd5f7559049268ad2dc6d81c4e39e9e36518766eaf7e342\n",
      "Successfully built python-Levenshtein\n",
      "Installing collected packages: python-Levenshtein\n",
      "Successfully installed python-Levenshtein-0.12.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fuzzywuzzy\n",
      "  Downloading https://files.pythonhosted.org/packages/43/ff/74f23998ad2f93b945c0309f825be92e04e0348e062026998b5eefef4c33/fuzzywuzzy-0.18.0-py2.py3-none-any.whl\n",
      "Installing collected packages: fuzzywuzzy\n",
      "Successfully installed fuzzywuzzy-0.18.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @hidden_cell\n",
    "# The project token is an authorization token that is used to access project resources like data sources, connections, and used by platform APIs.\n",
    "from project_lib import Project\n",
    "project = Project(project_id='507f7717-5906-4033-9cf8-a6309e2ee98f', project_access_token='p-f4abb7d1fb4c9c18621f64310211c00868d4a225')\n",
    "pc = project.project_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "import numpy as np\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share the notebook.\n",
    "client_bbb0ed0044694cf78b359319b07e0350 = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='PPZSlu0OUVHl8veQPlhoQVL7KdRfWnLFZJVZrMWlOF3b',\n",
    "    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n",
    "\n",
    "body1 = client_bbb0ed0044694cf78b359319b07e0350.get_object(Bucket='nycproject-donotdelete-pr-h0mj6hemybx914',Key='Small-restaurants_6162020.csv')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body1, \"__iter__\"): body1.__iter__ = types.MethodType( __iter__, body1 )\n",
    "\n",
    "body2 = client_bbb0ed0044694cf78b359319b07e0350.get_object(Bucket='nycproject-donotdelete-pr-h0mj6hemybx914',Key='foursquare_venues.csv')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body2, \"__iter__\"): body2.__iter__ = types.MethodType( __iter__, body2 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df=pd.read_csv(body1,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "foursquare=pd.read_csv(body2,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df.reset_index(drop=True, inplace=True)\n",
    "foursquare.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_df=pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 3000\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n"
     ]
    }
   ],
   "source": [
    "A=[2000,3000,4000,5000,6000,7000,8000,9000,10000,11000,12000]\n",
    "B=[3000,4000,5000,6000,7000,8000,9000,10000,11000,12000,12655]\n",
    "for a,b in zip(A,B):\n",
    "    print(a,b)\n",
    "    name_google=[]\n",
    "    name_foursquare=[]\n",
    "    address_google=[]\n",
    "    ratio_name=[]\n",
    "    ratio_address=[]\n",
    "    address_foursquare=[]\n",
    "    for i,name,vicinity in zip(small_df.index[a:b],small_df.name[a:b],small_df.vicinity[a:b]):\n",
    "        str2Match = name\n",
    "        strOptions = foursquare.name\n",
    "        str2Match2 = vicinity\n",
    "        strOptions2 = foursquare.address\n",
    "        # You can also select the string with the highest matching percentage\n",
    "        highest = process.extractOne(str2Match,strOptions)\n",
    "        name_google.append(name)\n",
    "        name_foursquare.append(str(highest[0]))\n",
    "        ratio_name.append(str(highest[1]))\n",
    "        \n",
    "        \n",
    "        highest2 = process.extractOne(str2Match2,strOptions2)\n",
    "        address_google.append(vicinity)\n",
    "        address_foursquare.append(str(highest2[0]))\n",
    "        ratio_address.append(str(highest2[1]))\n",
    "        \n",
    "        \n",
    "        print(i)\n",
    "\n",
    "    probe=pd.DataFrame()\n",
    "    probe[\"name_google\"]=name_google\n",
    "    probe[\"name_foursquare\"]=name_foursquare\n",
    "    probe[\"ratio_name\"]=ratio_name\n",
    "    probe[\"address_google\"]=address_google\n",
    "    probe[\"address_foursquare\"]=address_foursquare\n",
    "    probe[\"ratio_address\"]=ratio_address\n",
    "    \n",
    "    probe_df=probe_df.append(probe)\n",
    "    # Save dataframe as csv file to storage\n",
    "    project.save_data(data=probe_df.to_csv(index=False),file_name='{}-{}.csv'.format(a,b),overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
